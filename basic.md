---
layout: post
title:  "Oct 25 @ ENS"
author: "Hoeteck"
date:   2018-08-01 10:10:00
---

The next Paris Area Crypto Day will be held on 25.10.2018 (Thu) at
ENS.

* Amphi Jaur√®s, ENS (29 rue d'Ulm, level B1)
* Please [register](https://docs.google.com/forms/d/e/1FAIpQLSeop24A0asJvd73HvUH8zTDorfzPOpswA_pfcyVxc2zkctoMg/viewform) (free). Deadline 22.10.2018

<!--

### Program

| 10:00&nbsp;-&nbsp;10:05 | Welcome
| 10:05 - 11:05 | [Sarah Meiklejohn](#SM) 
| 11:15 - 11:45 | [Mary Maller](#MaMa) 
| 11:45 - 12:15 | [Julian Loss](#JL) 
| 12:15 - 14:00 | Lunch 
| 14:00 - 15:00 | [Ben Smith](#BS) 
| 15:00 - 15:30 | [Michele Minelli](#MiMi) Fast Homomorphic Evaluation of Deep Discretized Neural Networks
| 15:30 - 16:00 | Coffee Break
| 16:00 - 17:00 | [Adam O'Neill](#AO) Accessing Data While Preserving-Privacy

**Organizers.** Michel Abdalla and Hoeteck Wee ([ENS](https://crypto.di.ens.fr/web2py))

**Acknowledgements.** ERC [CryptoCloud](http://www.di.ens.fr/~pointche/CryptoCloud/) and [aSCEND](http://cordis.europa.eu/project/rcn/193658_en.html)

**<a name="SM"></a>title**
*Sarah Meiklejohn* (UCL)

**<a name="MaMa"></a>title**
*Mary Maller* (UCL)

**<a name="JL"></a>title**
*Julian Loss* (RUB)

**<a name="BS"></a>title**
*Ben Smith* (INRIA/LIX)

**<a name="MiMi"></a>Fast Homomorphic Evaluation of Deep Discretized Neural Networks**
*Michele Minelli* (ENS)

The rise of machine learning as a service multiplies scenarios where one faces a privacy dilemma: either sensitive user data must be revealed to the entity that evaluates the cognitive model (e.g., in the Cloud), or the model itself must be revealed to the user so that the evaluation can take place locally. Fully Homomorphic Encryption (FHE) offers an elegant way to reconcile these conflicting interests in the Cloud-based scenario and also preserve non-interactivity. However, due to the inefficiency of existing FHE schemes, most applications prefer to use Somewhat Homomorphic Encryption (SHE), where the complexity of the computation to be performed has to be known in advance, and the efficiency of the scheme depends on this global complexity.

In this paper, we present a new framework for homomorphic evaluation of neural networks, that we call FHE-DiNN, whose complexity is strictly linear in the depth of the network and whose parameters can be set beforehand. To obtain this scale-invariance property, we rely heavily on the bootstrapping procedure. We refine the recent FHE construction by Chillotti et al. (ASIACRYPT 2016) in order to increase the message space and apply the sign function (that we use to activate the neurons in the network) during the bootstrapping. We derive some empirical results, using TFHE library as a starting point, and classify encrypted images from the MNIST dataset with more than 96% accuracy in less than 1.7 seconds.

Finally, as a side contribution, we analyze and introduce some variations to the bootstrapping technique of Chillotti et al. that offer an improvement in efficiency at the cost of increasing the storage requirements.

(Joint work with Florian Bourse, Matthias Minihold and Pascal Paillier)

**<a name="AO"></a>Accessing Data While Preserving-Privacy**
*Adam O'Neill* (Georgetown)

End-to-end encryption promises to protect against data leaks and mass surveillance. But how can end-to-end encryption be reconciled with functionality like cloud computing, targeted advertising, and search? This talk will take a look at the specific case of secure outsourced databases, where a client wants to outsource its data storage to an untrusted server, ensuring privacy against the server while maintaining the ability to perform queries. There are a variety of cryptographic solutions proposed to this problem, ranging from those based on deterministic and order-preserving encryption to those based on oblivious RAM or fully-homomorphic encryption. Here we take a step back and identify fundamental ``leakage channels'' of such protocols, meaning the information leaked to the server about the client's data. We show that if these channels are ``exact'' then the server can fully reconstruct the client's data in some cases.  We then propose making these channels ``noisy'' and give some initial protocols in this direction, where the leakage is differentially private.

(Joint work with George Kellaris, George Kollios and Kobbi Nissim)


-->
